{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,roc_auc_score,precision_recall_curve,accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import keras\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "device_data = pd.read_csv(path+\"\\\\Data\\\\device_failure.csv\",encoding='ISO-8859-1')\n",
    "# device_data.describe()\n",
    "# device_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below plot tells you the data is highly imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishalra\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='failure', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(device_data[\"failure\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124494\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "print(device_data[\"failure\"].count())\n",
    "print(device_data[device_data[\"failure\"]==1][\"failure\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for failed devices are 0.085% of total data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# #Maintenance_bp=pd.DataFrame(Maintenance_bp,index=[0, 1, 2, 3,4,5,6,7,8,9])\n",
    "# device_data_corr=device_data.corr()\n",
    "# sns.heatmap(device_data_corr, annot=True)\n",
    "\n",
    "# sns.pairplot(device_data, hue='failure', palette='husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()\n",
    "obj_scaler = scalar.fit(device_data.iloc[:,3:])\n",
    "# device_data_scaled = pd.DataFrame(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_data_features = device_data.iloc[:,2:]\n",
    "labels = device_data.iloc[:,2:3]\n",
    "X_train_org,X_Unseen_features,y_train_org,y_Unseen_labels = train_test_split(device_data_features,labels,test_size =0.2,random_state=42)\n",
    "X_Unseen_features.drop([\"failure\"],axis=1,inplace=True)\n",
    "\n",
    "X_train = X_train_org.copy(deep=True)\n",
    "y_train = y_train_org.copy(deep=True)\n",
    "X_train.drop([\"failure\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train base model without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    scaled_data = pd.DataFrame(obj_scaler.transform(data))\n",
    "    return scaled_data\n",
    "\n",
    "\n",
    "def NN_model(X_train,y_train,X_test,y_test,eps,metric):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(9,input_dim=9,activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(15,activation=\"relu\"))\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[metric])\n",
    "\n",
    "    model.fit(X_train,y_train,epochs=eps)\n",
    "    preds=model.predict(X_test)\n",
    "    print(preds)\n",
    "#     preds=np.round(preds)\n",
    "#     print(classification_report(y_test,preds))\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_class(data):\n",
    "    return np.argmax(data),data[np.argmax(data)]\n",
    "\n",
    "def train_model(features_train,labels_train,features_val,labels_val):\n",
    "    rf =  RandomForestClassifier(n_estimators=100,\n",
    "                                class_weight='balanced')\n",
    "    rf.fit(X_sub_train,y_sub_train)\n",
    "    preds_on_val = rf.predict_proba(features_val)\n",
    "    return preds_on_val,rf\n",
    "\n",
    "def post_process_output(result,threshold):\n",
    "    df_output_org = pd.DataFrame(result,columns=[\"pass\",\"failure\"])#.apply(argmax_class)\n",
    "    df_output = df_output_org.T.apply(argmax_class).T\n",
    "    df_output = df_output.rename(columns={\"pass\":\"status\",\"failure\":\"proba\"})\n",
    "    df_output[\"status\"]=np.where(df_output[\"proba\"]<threshold,0,1)\n",
    "    return df_output[\"status\"],df_output_org\n",
    "\n",
    "\n",
    "def cross_validation_output(features_train,labels_train):\n",
    "    model =  RandomForestClassifier(n_estimators=100,\n",
    "                                class_weight='balanced')\n",
    "    cv_results  = cross_val_score(model,features_train,labels_train\n",
    "                ,scoring=\"f1\"\n",
    "                ,cv=10\n",
    "               )\n",
    "    \n",
    "    model.fit(features_train,labels_train) \n",
    "    return cv_results,model\n",
    "\n",
    "\n",
    "def model_output_unseen_data(model,X_unseen,y_unseen,threshold):\n",
    "    pred_on_test = model.predict_proba(X_unseen)\n",
    "    pred_on_test,df_output_org = post_process_output(pred_on_test,threshold)\n",
    "    print(\"F1 score on unseen data is %0.2f \\n\\n\" % (f1_score(y_unseen,pred_on_test)))\n",
    "    print(classification_report(y_unseen,pred_on_test))\n",
    "    print(confusion_matrix(y_unseen,pred_on_test))\n",
    "    \n",
    "    return 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sub_train,X_val,y_sub_train,y_val = train_test_split(X_train,y_train,test_size =0.2,random_state=42)\n",
    "# pred_on_val,rf_model = train_model(X_sub_train,y_sub_train,X_val,y_val)\n",
    "# pred_on_val,df_output_org = post_process_output(pred_on_val,0.98)\n",
    "# print(classification_report(y_val,pred_on_val))\n",
    "# print(confusion_matrix(y_val,pred_on_val))\n",
    "# X_sub_train.drop([\"failure\"],axis=1,inplace=True)\n",
    "# X_val.drop([\"failure\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10 fold cross validation using f1 as scoring\n",
    "        Algo - Randomforestclassifier\n",
    "        parameter : n_estimators = 100, class_weights=\"balance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'failure'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:41\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'failure'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result,rf_model \u001b[38;5;241m=\u001b[39m cross_validation_output(X_train,\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfailure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean f1 score of \u001b[39m\u001b[38;5;132;01m%0.2f\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (result\u001b[38;5;241m.\u001b[39mmean()))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'failure'"
     ]
    }
   ],
   "source": [
    "result,rf_model = cross_validation_output(X_train,y_train[\"failure\"].values)\n",
    "print(\"Mean f1 score of %0.2f \" % (result.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.00      0.00     24881\n",
      "           1       0.00      0.83      0.00        18\n",
      "\n",
      "    accuracy                           0.00     24899\n",
      "   macro avg       0.47      0.42      0.00     24899\n",
      "weighted avg       0.95      0.00      0.00     24899\n",
      "\n",
      "[[   55 24826]\n",
      " [    3    15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_unseen_data(rf_model,X_Unseen_features,y_Unseen_labels[\"failure\"].values,0.83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# modl = NN_model(X_sub_train,y_sub_train,X_val,y_val,10,keras.metrics.Recall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "\n",
    "##### Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure=X_train_org[X_train_org[\"failure\"]==1]\n",
    "df_pass=X_train_org[X_train_org[\"failure\"]==0]\n",
    "X_under_sample = df_pass.sample(n=df_failure.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_train_data = pd.concat([X_under_sample,df_failure],axis=0)\n",
    "X_train=new_train_data.drop([\"failure\"],axis=1)\n",
    "y_train=new_train_data[\"failure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sub_train,X_val,y_sub_train,y_val = train_test_split(new_train_data,new_train_data[\"failure\"],test_size=0.2,stratify=new_train_data[\"failure\"])\n",
    "# X_sub_train.drop([\"failure\"],axis=1,inplace=True)\n",
    "# X_val.drop([\"failure\"],axis=1,inplace=True)\n",
    "# pred_on_val,rf_model = train_model(X_sub_train,y_sub_train,X_val,y_val)\n",
    "# pred_on_val,df_output_org = post_process_output(pred_on_val,0.83)\n",
    "# print(classification_report(y_val,pred_on_val))\n",
    "# print(confusion_matrix(y_val,pred_on_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score of 0.82\n"
     ]
    }
   ],
   "source": [
    "result,rf_model = cross_validation_output(X_train,y_train.values)\n",
    "print(\"Mean f1 score of %0.2f\" % (result.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on unseen data is 0.00 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.45     24881\n",
      "           1       0.00      0.89      0.00        18\n",
      "\n",
      "    accuracy                           0.29     24899\n",
      "   macro avg       0.50      0.59      0.23     24899\n",
      "weighted avg       1.00      0.29      0.45     24899\n",
      "\n",
      "[[ 7191 17690]\n",
      " [    2    16]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_unseen_data(rf_model,X_Unseen_features,y_Unseen_labels[\"failure\"].values,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trianed_model = NN_model(X_sub_train,y_sub_train,X_val,y_val,100,keras.metrics.Recall())\n",
    "# rf =  RandomForestClassifier()\n",
    "# rf.fit(X_sub_train,y_sub_train)\n",
    "# pred_on_test = rf.predict_proba(X_val)\n",
    "# pred_on_test = np.round(pred_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y_val,df_output[\"status\"]))\n",
    "# print(confusion_matrix(y_val,df_output[\"status\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_on_test = rf_model.predict_proba(X_test)\n",
    "# pred_on_test,df_output_org = post_process_output(pred_on_test,0.95)\n",
    "# print(classification_report(y_test,pred_on_test))\n",
    "# print(confusion_matrix(y_test,pred_on_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "\n",
    "##### With scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=scale_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score of 0.81\n"
     ]
    }
   ],
   "source": [
    "result,rf_model = cross_validation_output(X_train,y_train.values)\n",
    "print(\"Mean f1 score of %0.2f\" % (result.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishalra\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on unseen data is 0.01 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     24881\n",
      "           1       0.01      0.67      0.01        18\n",
      "\n",
      "    accuracy                           0.94     24899\n",
      "   macro avg       0.50      0.80      0.49     24899\n",
      "weighted avg       1.00      0.94      0.97     24899\n",
      "\n",
      "[[23288  1593]\n",
      " [    6    12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_unseen_data(rf_model,X_Unseen_features,y_Unseen_labels[\"failure\"].values,0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sub_train = scale_data(X_sub_train)\n",
    "# X_val = scale_data(X_val)\n",
    "# trianed_model = NN_model(X_sub_train,y_sub_train,X_val,y_val,100,keras.metrics.Recall())\n",
    "# pred_on_test = trianed_model.predict(X_test)\n",
    "# # pred_on_test = np.round(pred_on_test)\n",
    "# print(classification_report(y_test,pred_on_test))\n",
    "# print(confusion_matrix(y_test,pred_on_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_on_val,rf_model = train_model(X_sub_train,y_sub_train,X_val,y_val)\n",
    "# pred_on_val,df_output_org = post_process_output(pred_on_val,0.83)\n",
    "# print(classification_report(y_val,pred_on_val))\n",
    "# print(confusion_matrix(y_val,pred_on_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_on_test = rf_model.predict_proba(X_test)\n",
    "# pred_on_test,df_output_org = post_process_output(pred_on_test,0.81)\n",
    "# print(classification_report(y_test,pred_on_test))\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test,pred_on_test).ravel()\n",
    "# # print(tn, fp, fn, tp)\n",
    "# print(confusion_matrix(y_test,pred_on_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling \n",
    "##### Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure_oversample=df_failure.sample(df_pass.shape[0],replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = pd.concat([df_failure_oversample,df_pass],axis=0)\n",
    "X_train=new_train_data.drop([\"failure\"],axis=1)\n",
    "y_train=new_train_data[\"failure\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score of 1.00\n"
     ]
    }
   ],
   "source": [
    "result,rf_model = cross_validation_output(X_train,y_train.values)\n",
    "print(\"Mean f1 score of %0.2f\" % (result.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on unseen data is 0.00 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.00      0.00     24881\n",
      "           1       0.00      0.94      0.00        18\n",
      "\n",
      "    accuracy                           0.00     24899\n",
      "   macro avg       0.48      0.47      0.00     24899\n",
      "weighted avg       0.95      0.00      0.00     24899\n",
      "\n",
      "[[   21 24860]\n",
      " [    1    17]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_unseen_data(rf_model,X_Unseen_features,y_Unseen_labels[\"failure\"].values,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_sub_train,X_val,y_sub_train,y_val = train_test_split(new_train_data,new_train_data[\"failure\"],test_size=0.2,stratify=new_train_data[\"failure\"])\n",
    "# X_sub_train.drop([\"failure\"],axis=1,inplace=True)\n",
    "# X_val.drop([\"failure\"],axis=1,inplace=True)\n",
    "# trianed_model = NN_model(X_sub_train,y_sub_train,X_val,y_val,100,keras.metrics.Recall())\n",
    "# pred_on_test = trianed_model.predict(X_test)\n",
    "# pred_on_test = np.round(pred_on_test)\n",
    "# print(classification_report(y_test,pred_on_test))\n",
    "# print(confusion_matrix(y_test,pred_on_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_on_val,rf_model = train_model(X_sub_train,y_sub_train,X_val,y_val)\n",
    "# pred_on_val,df_output_org = post_process_output(pred_on_val,0.83)\n",
    "# print(classification_report(y_val,pred_on_val))\n",
    "# print(confusion_matrix(y_val,pred_on_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_on_test = rf_model.predict_proba(X_test)\n",
    "# pred_on_test,df_output_org = post_process_output(pred_on_test,0.83)\n",
    "# print(classification_report(y_test,pred_on_test))\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test,pred_on_test).ravel()\n",
    "# print(tn, fp, fn, tp)\n",
    "# print(confusion_matrix(y_test,pred_on_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling \n",
    "##### With scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=scale_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score of 1.00\n"
     ]
    }
   ],
   "source": [
    "result,rf_model = cross_validation_output(X_train,y_train.values)\n",
    "print(\"Mean f1 score of %0.2f\" % (result.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishalra\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on unseen data is 0.00 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.03      0.06     24881\n",
      "           1       0.00      0.39      0.00        18\n",
      "\n",
      "    accuracy                           0.03     24899\n",
      "   macro avg       0.49      0.21      0.03     24899\n",
      "weighted avg       0.99      0.03      0.06     24899\n",
      "\n",
      "[[  794 24087]\n",
      " [   11     7]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_unseen_data(rf_model,X_Unseen_features,y_Unseen_labels[\"failure\"].values,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sub_train = scale_data(X_sub_train)\n",
    "# X_val = scale_data(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_on_val,rf_model = train_model(X_sub_train,y_sub_train,X_val,y_val)\n",
    "# pred_on_val,df_output_org = post_process_output(pred_on_val)\n",
    "# print(classification_report(y_val,pred_on_val))\n",
    "# print(confusion_matrix(y_val,pred_on_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_on_test = rf_model.predict_proba(X_test)\n",
    "# pred_on_test,df_output_org = post_process_output(pred_on_test)\n",
    "# print(classification_report(y_test,pred_on_test))\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test,pred_on_test).ravel()\n",
    "# print(tn, fp, fn, tp)\n",
    "# print(confusion_matrix(y_test,pred_on_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy=\"minority\")\n",
    "# X_train_sm,y_train_sm  = .fit_sample(X_train.iloc[:,1:],X_train.iloc[:,0:1])\n",
    "X_train_sm,y_train_sm = sm.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score of 1.00\n"
     ]
    }
   ],
   "source": [
    "result,rf_model = cross_validation_output(X_train_sm,y_train_sm.values)\n",
    "print(\"Mean  f1 score of %0.2f\" % (result.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on unseen data is 0.00 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.00      0.00     24881\n",
      "           1       0.00      0.83      0.00        18\n",
      "\n",
      "    accuracy                           0.00     24899\n",
      "   macro avg       0.47      0.42      0.00     24899\n",
      "weighted avg       0.94      0.00      0.00     24899\n",
      "\n",
      "[[   46 24835]\n",
      " [    3    15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_unseen_data(rf_model,X_Unseen_features,y_Unseen_labels[\"failure\"].values,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sub_train,X_val,y_sub_train,y_val = train_test_split(X_train_sm,y_train_sm,test_size=0.2)\n",
    "# # X_sub_train.drop([\"failure\"],axis=1,inplace=True)\n",
    "# # X_val.drop([\"failure\"],axis=1,inplace=True)\n",
    "# pred_on_val,rf_model = train_model(X_sub_train,y_sub_train,X_val,y_val)\n",
    "\n",
    "# pred_on_val,df_output_org = post_process_output(pred_on_val,0.95)\n",
    "# print(classification_report(y_val,pred_on_val))\n",
    "# print(confusion_matrix(y_val,pred_on_val))\n",
    "\n",
    "# cv_results  = cross_val_score(rf_model,X_train_sm,y_train_sm\n",
    "#                 ,scoring=\"f1\"\n",
    "#                 ,cv=10\n",
    "#                )\n",
    "\n",
    "# pred_on_test = rf_model.predict_proba(X_test)\n",
    "# pred_on_test,df_output_org = post_process_output(pred_on_test,0.83)\n",
    "# print(classification_report(y_test,pred_on_test))\n",
    "# print(confusion_matrix(y_test,pred_on_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = scale_data(X_train_sm)\n",
    "# X_val = scale_data(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean  f1 score of 1.00\n"
     ]
    }
   ],
   "source": [
    "result,rf_model = cross_validation_output(X_train_sm,y_train_sm.values)\n",
    "print(\"Mean  f1 score of %0.2f\" % (result.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Unseen_features = scale_data(X_Unseen_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on unseen data is 0.00 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.00      0.01     24881\n",
      "           1       0.00      0.83      0.00        18\n",
      "\n",
      "    accuracy                           0.00     24899\n",
      "   macro avg       0.48      0.42      0.00     24899\n",
      "weighted avg       0.96      0.00      0.01     24899\n",
      "\n",
      "[[   70 24811]\n",
      " [    3    15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_unseen_data(rf_model,X_Unseen_features,y_Unseen_labels[\"failure\"].values,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
